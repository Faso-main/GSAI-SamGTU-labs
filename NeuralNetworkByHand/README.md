# Описание реализации нейронной сети

## Класс `Neuron` (отдельный нейрон сети)

### Методы:

- **`__init__(self, num_inputs)`**  
  Конструктор нейрона:
  - Принимает количество входящих связей `num_inputs`
  - Инициализирует:
    - Случайные веса `self.weights` (диапазон [-1, 1])
    - Случайное смещение `self.bias` (диапазон [-1, 1])
    - Начальные значения выхода (`self.output = 0`) и ошибки (`self.error = 0`)

- **`sigmoid(self, x)`**  
  Реализует сигмоидальную функцию активации:
  - Преобразует взвешенную сумму в значение ∈ [0, 1]

- **`sigmoid_derivative(self, x)`**  
  Вычисляет производную сигмоидальной функции:
  - Используется для обратного распространения ошибки

- **`forward(self, inputs)`**  
  Прямой проход:
  1. Умножает входы на веса и суммирует
  2. Добавляет смещение
  3. Применяет сигмоиду → сохраняет в `self.output`
  4. Сохраняет входы (`self.inputs`) для обратного распространения

- **`backward(self, error)`**  
  Обратное распространение ошибки:
  1. Принимает ошибку от следующего слоя
  2. Умножает на производную сигмоиды
  3. Сохраняет как `self.error`
  4. Возвращает вычисленную ошибку

- **`update_weights(self, learning_rate)`**  
  Обновление весов:
  - Корректирует веса и смещение на основе:
    - Скорости обучения `learning_rate`
    - Ошибки нейрона
    - Входных значений

## Класс `NeuralNetwork` (многослойная нейронная сеть)

### Методы:

- **`__init__(self, layers)`**  
  Конструктор сети:
  - Принимает список `layers` (например, [8, 4, 1])
  - Создает слои нейронов:
    - Каждый нейрон в слое N имеет `layers[N-1]` входов

- **`forward(self, inputs)`**  
  Прямой проход через сеть:
  1. Передает входные данные через все слои
  2. Возвращает выход последнего слоя

- **`backward(self, target)`**  
  Обратное распространение:
  1. Вычисляет ошибку выходного слоя (target - output)
  2. Распространяет ошибку назад по слоям
  3. Для скрытых слоев:
     - Ошибка = взвешенная сумма ошибок следующего слоя

- **`update(self, learning_rate)`**  
  Обновление весов сети:
  - Вызывает `update_weights` для всех нейронов

- **`train(self, X, y, epochs=1000, learning_rate=0.1)`**  
  Обучение сети:
  - Цикл по `epochs`:
    1. Прямой проход (`forward`)
    2. Обратное распространение (`backward`)
    3. Обновление весов (`update`)
  - Периодически выводит среднюю ошибку

## Пример использования (медицинская диагностика)

```python
# Данные (нормализованные)
medical_data = [...]  # 8 признаков
labels = [...]        # 0/1 (нет/есть диабет)

# Создание сети (8-4-1)
nn = NeuralNetwork([8, 4, 1])

# Обучение
nn.train(medical_data, labels, epochs=1000)

# Тестирование
test_patient = [...]
prediction = nn.forward(test_patient)
print(f"Вероятность диабета: {prediction[0]:.2f}")

# Бинарный вывод
diagnosis = "Есть диабет" if prediction[0] > 0.5 else "Нет диабета"
print(diagnosis)